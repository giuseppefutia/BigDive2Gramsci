{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph-representation-ml-numpy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuseppefutia/BigDive2Gramsci/blob/master/graph_representation_ml_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eh6QnZM-hie2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Graph Representation for Machine Learning Using Numpy\n",
        "Machine learning algorithms are able to process data in the form of matrices. For such reasons, we need to understand how we can represent graph using matrices.\n",
        "\n",
        "Consider the following graph example:\n",
        "\n",
        "![Graph example](http://graphonline.ru/tmp/saved/RF/RFAOxGXmjawkuiWO.png =300x)\n",
        "\n",
        "We can represent this graph using the following matrices.\n",
        "\n",
        "## Adjacency Matrix\n",
        "\n",
        "An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. If the graph is undirected, the adjacency matrix is symmetric. The adjacency matrix of our graph example is the following:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  0. & 1. & 1. & 1 \\\\ \n",
        "  1. & 0. & 0. & 0 \\\\ \n",
        "  1. & 0. & 0. & 1 \\\\ \n",
        "  1. & 0. & 1. & 0 \\\\ \n",
        "\\end{bmatrix}$\n",
        "\n",
        "## Incidence Matrix\n",
        "An incidence matrix is a matrix that shows the relationship between two classes of objects (nodes and objects). Incidence matrices can describe directed and undirected graphs.\n",
        "\n",
        "In graph theory, an undirected graph (like our example) can be represented using different types of incidence matrices:\n",
        "* **unoriented incidence matrix**\n",
        "* **oriented incidence matrix**\n",
        "\n",
        "The unoriented incidence matrix (or simpy incidence matrix) is a $n × m$ matrix $B$, where $n$ and $m$ are the numbers of vertices and edges respectively, such that $B_{i,j} = 1$ if the vertex $v_i$ and edge $e_j$ are incident and 0 otherwise.\n",
        "\n",
        "The (unoriented) incidence matrix of our graph example is the following:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  1. & 1. & 1. & 0 \\\\\n",
        "  1. & 0. & 0. & 0 \\\\\n",
        "  0. & 0. & 1. & 1 \\\\\n",
        "  0. & 1. & 0. & 1 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "In this matrix we see that the sum of each column is equal to 2. This happens because all couples of vertices in the entire graph are linked by only one edge.\n",
        "\n",
        "\n",
        "The incidence matrix of a directed graph is a $n × m$ matrix $B$ where $n$ and $m$ are the number of vertices and edges respectively, such that $B_{i,j} = −1$ if the edge $e_j$ leaves vertex $v_i$, 1 if it enters vertex $v_i$ and 0 otherwise\n",
        "\n",
        "\n",
        "The oriented incidence matrix of an undirected graph is the incidence matrix, in the sense of directed graphs, of any orientation of the graph. That is, in the column of edge $e$, there is one $1$ in the row corresponding to one vertex of e and one $−1$ in the row corresponding to the other vertex of e, and all other rows have $0$. \n",
        "\n",
        "The oriented incidence matrix is unique up to negation of any of the columns, since negating the entries of a column corresponds to reversing the orientation of an edge.\n",
        "\n",
        "The oriented incidence matrix of our graph example is the following:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  -1. & -1. & -1. &  0. \\\\\n",
        "   1. &  0. &  0. &  0. \\\\\n",
        "   0. &  0. &  1. & -1. \\\\\n",
        "   0. &  1. &  0. & -1. \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "\n",
        "## Degree Matrix\n",
        "The degree matrix is a diagonal matrix which contains information about the degree of each vertex—that is, the number of edges attached to each vertex.\n",
        "\n",
        "The degree is used together with the adjacency matrix to construct the Laplacian matrix of a graph (that we explore in the following section). The degree matrix of our graph example is the following: \n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  3. & 0. & 0. & 0 \\\\ \n",
        "  0. & 1. & 0. & 0 \\\\ \n",
        "  0. & 0. & 2. & 0 \\\\ \n",
        "  0. & 0. & 0. & 2 \\\\ \n",
        "\\end{bmatrix}$\n",
        "\n",
        "## Laplacian Matrix\n",
        "The Laplacian matrix, sometimes called admittance matrix, Kirchhoff matrix or discrete Laplacian, is a matrix representation of a graph. It can be used to calculate the number of spanning trees for a given graph and to to construct low dimensional embeddings, which can be useful for a variety of machine learning applications.\n",
        "\n",
        "Given a simple graph $G$ with $n$ vertices, its Laplacian matrix ${\\textstyle L_{n\\times n}} $ is defined as:\n",
        "\n",
        "* ${\\displaystyle L=D-A,}$ where $D$ is the degree matrix and $A$ is the adjacency matrix of the graph.\n",
        "* $L = I * I.T$ where $I$ is the oriented incidence matrix of our undirected graph.\n",
        "\n",
        "Let's see the representation of the laplacian matrix with the degree matrix and the adjacency matrix, on the one side, and with the oriented incidence matrix, on the other side. We exploit numpy and make some tests using networkx. \n"
      ]
    },
    {
      "metadata": {
        "id": "JsWr7rCahcqp",
        "colab_type": "code",
        "outputId": "50b29dd9-bd53-466a-8530-d1c0f2de6e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "# Adjacency matrix\n",
        "A = np.matrix([\n",
        "    [0, 1, 1, 1],\n",
        "    [1, 0, 0, 0], \n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Adjacency matrix')\n",
        "print(A)\n",
        "\n",
        "# Incidence matrix (unoriented)\n",
        "I_u = np.matrix([\n",
        "    [1, 1, 1, 0],\n",
        "    [1, 0, 0, 0],\n",
        "    [0, 0, 1, 1],\n",
        "    [0, 1, 0, 1]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Incidence matrix (unoriented)')\n",
        "print(I_u)\n",
        "\n",
        "# Incidence matrix (oriented)\n",
        "I_o = np.matrix([\n",
        "    [-1, -1, -1,  0],\n",
        "    [ 1,  0,  0,  0],\n",
        "    [ 0,  0,  1, -1],\n",
        "    [ 0,  1,  0,  1]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Incidence matrix (oriented)')\n",
        "print(I_o)\n",
        "\n",
        "# Degree matrix\n",
        "D = np.matrix([\n",
        "    [3, 0, 0, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 2, 0],\n",
        "    [0, 0, 0, 2]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Degree matrix')\n",
        "print(D)\n",
        "\n",
        "# The degree matrix can be computed from the adjacency matrix\n",
        "D_from_A = np.array(np.sum(A, axis=0))[0]\n",
        "D_from_A = np.matrix(np.diag(D_from_A))\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Computed degree matrix from adjacency one')\n",
        "print(D_from_A)\n",
        "\n",
        "# Laplacian matrix computed with degree and adjacency matrices\n",
        "L = D - A\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Laplacian matrix computed with degree and adjacency matrices')\n",
        "print(L)\n",
        "\n",
        "# Laplacian matrix computed with the oriented incidence matrix\n",
        "L = I_o * I_o.T\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Laplacian matrix computed with the oriented incidence matrix')\n",
        "print(L)\n",
        "\n",
        "# Test using networkx\n",
        "# Compute the networkx graph using the adjacency matrix\n",
        "# Then compute the laplacian matrix\n",
        "G = nx.from_numpy_matrix(A)\n",
        "L = nx.laplacian_matrix(G)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Laplacian matrix computed with networkx')\n",
        "print(L.toarray())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adjacency matrix\n",
            "[[0. 1. 1. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 1.]\n",
            " [1. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "Incidence matrix (unoriented)\n",
            "[[1. 1. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 1.]\n",
            " [0. 1. 0. 1.]]\n",
            "\n",
            "\n",
            "Incidence matrix (oriented)\n",
            "[[-1. -1. -1.  0.]\n",
            " [ 1.  0.  0.  0.]\n",
            " [ 0.  0.  1. -1.]\n",
            " [ 0.  1.  0.  1.]]\n",
            "\n",
            "\n",
            "Degree matrix\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Computed degree matrix from adjacency one\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Laplacian matrix computed with degree and adjacency matrices\n",
            "[[ 3. -1. -1. -1.]\n",
            " [-1.  1.  0.  0.]\n",
            " [-1.  0.  2. -1.]\n",
            " [-1.  0. -1.  2.]]\n",
            "\n",
            "\n",
            "Laplacian matrix computed with the oriented incidence matrix\n",
            "[[ 3. -1. -1. -1.]\n",
            " [-1.  1.  0.  0.]\n",
            " [-1.  0.  2. -1.]\n",
            " [-1.  0. -1.  2.]]\n",
            "\n",
            "\n",
            "Laplacian matrix computed with networkx\n",
            "[[ 3. -1. -1. -1.]\n",
            " [-1.  1.  0.  0.]\n",
            " [-1.  0.  2. -1.]\n",
            " [-1.  0. -1.  2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PCeov6OMiBMW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Through the observation of the laplacian matrix of a simple graph (no loop or multiple edges for each node), we can notice that\n",
        "\n",
        "\n",
        "$L_{i,j}: = \\begin{cases} deg(v_i) \\qquad \\text{ if } i=j \\\\\n",
        "                                      -1 \\qquad \\qquad \\text{ if } i \\ne j  \\\\\n",
        "                                      0 \\qquad \\qquad \\text{ otherwise } \\end{cases} $\n",
        "\n",
        "\n",
        "\n",
        "### Symmetric Normalized Laplacian Matrix\n",
        "\n",
        "We can also obtain the **symmetric normalized laplacian matrix**, that is defined as follows:\n",
        "\n",
        "$L^{sym} := D^{-1/2}LD^{-1/2}=I-D^{-1/2}AD^{-1/2}$\n",
        "\n",
        "The elements of this formula are the following:\n",
        "* $D^{-1/2}$ is a diagonal matrix where diagonal values correspond to the reciprocal square root  of diagonal values in root (see the code below for more details) \n",
        "* $L$ is the laplacian matrix (not normalized)\n",
        "* $I$ is the unit matrix\n",
        "* $A$ is the adjacency *matrix*\n",
        "\n",
        "Let's compute the symmetric normalized laplacian using numpy (and test the results using networkx):"
      ]
    },
    {
      "metadata": {
        "id": "woRoIAEsiLnt",
        "colab_type": "code",
        "outputId": "ce5804a5-e1f7-4591-e6af-82ad885bc68c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "# Adjacency Matrix - Size (4,4)\n",
        "A = np.matrix([\n",
        "    [0, 1, 1, 1],\n",
        "    [1, 0, 0, 0], \n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Adjacency matrix')\n",
        "print(A)\n",
        "\n",
        "# The Degree Matrix can be computed from the Adjacency Matrix\n",
        "D = np.array(np.sum(A, axis=0))[0]\n",
        "D = np.matrix(np.diag(D))\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Computed degree matrix from adjacency one')\n",
        "print(D)\n",
        "\n",
        "# Laplacian matrix\n",
        "L = D-A\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Laplacian matrix')\n",
        "print(L)\n",
        "\n",
        "# Symmetric normalized laplacian\n",
        "# Issue: when I compute reciprocal of square roots of all matrix values I obtain\n",
        "# inf in case of 0 (this happens in the cases where i!=j)\n",
        "# For this reason, I need to apply a hack to obtain D^-1/2\n",
        "# Here I show the computation of the left side of the equation\n",
        "D_hat = 1 / np.sqrt(D)\n",
        "D_hat = D_hat.diagonal()\n",
        "D_hat = np.squeeze(np.asarray(D_hat))\n",
        "D_hat = np.matrix(np.diag(D_hat))\n",
        "L_left = D_hat * L * D_hat\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Symmetric normalized laplacian matrix, left side of the equation')\n",
        "print(L_left)\n",
        "\n",
        "# Here I show the computation of the right side of the equation\n",
        "# Construct the unit matrix\n",
        "I = np.matrix([\n",
        "    [1, 0, 0, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 1, 0],\n",
        "    [0, 0, 0, 1]\n",
        "])\n",
        "L_right = I - D_hat * A * D_hat\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Symmetric normalized laplacian matrix, right side of the equation')\n",
        "print(L_right)\n",
        "\n",
        "# To test the correctness of our numpy implementation we exploit the networkx library\n",
        "# Numpy adjacency matrix as networkx graph\n",
        "G = nx.from_numpy_matrix(A)\n",
        "L = nx.laplacian_matrix(G)\n",
        "N = nx.normalized_laplacian_matrix(G)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Symmetric normalized laplacian matrix using networkx (for checking)')\n",
        "print(N.toarray())\n",
        "\n",
        "L_sym = N.toarray()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adjacency matrix\n",
            "[[0. 1. 1. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 1.]\n",
            " [1. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "Computed degree matrix from adjacency one\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Laplacian matrix\n",
            "[[ 3. -1. -1. -1.]\n",
            " [-1.  1.  0.  0.]\n",
            " [-1.  0.  2. -1.]\n",
            " [-1.  0. -1.  2.]]\n",
            "\n",
            "\n",
            "Symmetric normalized laplacian matrix, left side of the equation\n",
            "[[ 1.         -0.57735027 -0.40824829 -0.40824829]\n",
            " [-0.57735027  1.          0.          0.        ]\n",
            " [-0.40824829  0.          1.         -0.5       ]\n",
            " [-0.40824829  0.         -0.5         1.        ]]\n",
            "\n",
            "\n",
            "Symmetric normalized laplacian matrix, right side of the equation\n",
            "[[ 1.         -0.57735027 -0.40824829 -0.40824829]\n",
            " [-0.57735027  1.          0.          0.        ]\n",
            " [-0.40824829  0.          1.         -0.5       ]\n",
            " [-0.40824829  0.         -0.5         1.        ]]\n",
            "\n",
            "\n",
            "Symmetric normalized laplacian matrix using networkx (for checking)\n",
            "[[ 1.         -0.57735027 -0.40824829 -0.40824829]\n",
            " [-0.57735027  1.          0.          0.        ]\n",
            " [-0.40824829  0.          1.         -0.5       ]\n",
            " [-0.40824829  0.         -0.5         1.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "UGz1Wi_y9Scv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The elements of symmetric normalized laplacian matrix are given by:\n",
        "\n",
        "$L^{sym}_{i,j}: = \\begin{cases} 1 \\qquad \\qquad \\qquad \\qquad \\text{ if } i=j \\text{ and } deg(v_i) \\neq 0\\\\\n",
        "                                      -\\frac{1}{\\sqrt{deg(v_i) deg(v_j)}}  \\qquad \\text{ if } i \\ne j  \\\\\n",
        "                                      0 \\qquad \\qquad \\qquad \\qquad \\text{ otherwise } \\end{cases} $\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UU70D0eTS6ju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Walk Normalized Laplacian\n",
        "\n",
        "The random walk normalized Laplacian is defined as:\n",
        "\n",
        "$ L^{\\text{rw}}:=D^{-1}L $\n",
        "\n",
        "The name of the random-walk normalized Laplacian comes from the fact that this matrix is $ L^{\\text{rw}}=I-P $, where $ P=D^{-1}A $ is simply the transition matrix of a random walker on the graph. \n",
        "\n",
        "Another definition is the following:\n",
        "\n",
        "$ L^{\\text{rw}} = I - D^{-1/2} (I - L^{sym}) D^{-1/2} $\n",
        "\n",
        "Let's compute the random walk normalized laplacian in numpy: "
      ]
    },
    {
      "metadata": {
        "id": "UBG3aid3TDbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "b07002b4-549f-4659-d67a-ebaa6d54d6f2"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Adjacency matrix\n",
        "A = np.matrix([\n",
        "    [0, 1, 1, 1],\n",
        "    [1, 0, 0, 0], \n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Adjacency matrix')\n",
        "print(A)\n",
        "\n",
        "# The degree matrix can be computed from the adjacency matrix\n",
        "D = np.array(np.sum(A, axis=0))[0]\n",
        "D = np.matrix(np.diag(D))\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Computed degree matrix from adjacency one')\n",
        "print(D)\n",
        "\n",
        "# Square root of degree matrix\n",
        "D_sqrt = np.sqrt(D)\n",
        "D_sqrt = D_sqrt.diagonal()\n",
        "D_sqrt = np.squeeze(np.asarray(D_sqrt))\n",
        "D_sqrt = np.matrix(np.diag(D_sqrt))\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Square root of degree matrix')\n",
        "print(D_sqrt)\n",
        "\n",
        "# Laplacian matrix computed with degree and adjacency matrices\n",
        "L = D - A\n",
        "\n",
        "# Diagonal matrix where diagonal entries are reciprocal of the corresponding\n",
        "# positive diagonal entries of the degree matrix\n",
        "D_inv = 1 / D\n",
        "D_inv = D_inv.diagonal()\n",
        "D_inv = np.squeeze(np.asarray(D_inv))\n",
        "D_inv = np.matrix(np.diag(D_inv))\n",
        "L_rw = D_inv * L\n",
        "\n",
        "# Random walk normalized laplacian\n",
        "print()\n",
        "print()\n",
        "print('Random walk normalized laplacian (D_inv * L)')\n",
        "print(L_rw)\n",
        "\n",
        "P = D_inv * A\n",
        "L_rw = I - P\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Random walk normalized laplacian (I - P) where P = D_inv * A')\n",
        "print(L_rw)\n",
        "\n",
        "# To compute L_sym you need to run the previous window\n",
        "L_rw = I - D_hat * (I - L_sym) * D_sqrt\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Random walk normalized laplacian (I - D_hat * (I - L_sym) * D_sqrt)')\n",
        "print(L_rw)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adjacency matrix\n",
            "[[0. 1. 1. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 1.]\n",
            " [1. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "Computed degree matrix from adjacency one\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Square root of degree matrix\n",
            "[[1.73205081 0.         0.         0.        ]\n",
            " [0.         1.         0.         0.        ]\n",
            " [0.         0.         1.41421356 0.        ]\n",
            " [0.         0.         0.         1.41421356]]\n",
            "\n",
            "\n",
            "Random walk normalized laplacian (D_inv * L)\n",
            "[[ 1.         -0.33333333 -0.33333333 -0.33333333]\n",
            " [-1.          1.          0.          0.        ]\n",
            " [-0.5         0.          1.         -0.5       ]\n",
            " [-0.5         0.         -0.5         1.        ]]\n",
            "\n",
            "\n",
            "Random walk normalized laplacian (I - P) where P = D_inv * A\n",
            "[[ 1.         -0.33333333 -0.33333333 -0.33333333]\n",
            " [-1.          1.          0.          0.        ]\n",
            " [-0.5         0.          1.         -0.5       ]\n",
            " [-0.5         0.         -0.5         1.        ]]\n",
            "\n",
            "\n",
            "Random walk normalized laplacian (I - D_hat * (I - L_sym) * D_sqrt)\n",
            "[[ 1.         -0.33333333 -0.33333333 -0.33333333]\n",
            " [-1.          1.          0.          0.        ]\n",
            " [-0.5         0.          1.         -0.5       ]\n",
            " [-0.5         0.         -0.5         1.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "h21PCWBYfF5z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The matrix element of the random walk normalized laplacian are the following:\n",
        "\n",
        "The elements of $L$ are given by:\n",
        "\n",
        "$L^{sym}_{i,j}: = \\begin{cases} 1 \\qquad \\qquad  \\qquad \\text{ if } i=j \\text{ and } deg(v_i) \\neq 0\\\\\n",
        "                                      -\\frac{1}{\\sqrt{deg(v_i)}}  \\qquad \\text{ if } i \\ne j \\text{ and } v_i \\text{ is adjacent to } v_j   \\\\\n",
        "                                      0 \\qquad \\qquad \\qquad  \\text{ otherwise } \\end{cases} $\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RlDRqB6wj5-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Walks on Graph to Compute the Reduce Adjacency Matrix\n",
        "As an aside about random walks on graphs, consider a simple undirected graph. \n",
        "\n",
        "Consider the probability that the walker is at the vertex $i$ at time $t$, given the probability distribution that he was at vertex $j$ at time $t − 1$ (assuming a uniform chance of taking a step along any of the edges attached to a given vertex):\n",
        "\n",
        "$p(t) = AD^{-1}p(t-1) $\n",
        "\n",
        "This relation can be rewrite as follows:\n",
        "\n",
        "$ D^{-1/2} p(t) = [D^{-1/2}AD^{-1/2}] D^{-1/2}p(t-1) $ \n",
        "\n",
        "$A_{\\text{reduced}} = D^{-1/2}AD^{-1/2} $ is a symmetric matrix called the reduced adjacency matrix. So, taking steps on this random walk requires taking powers of $A_{\\text{reduced}}$.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pq6nOhYlygP2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reduced Adjacency Matrix and Graph Convolutional Networks\n",
        "To understand the role of reduced adjacency matrix in machine learning on graphs we have to pick the main principles behind Graph Convolutional Networks (GCNs) that are one of the most powerful machine learning models for graphs.\n",
        "\n",
        "Let' s consider the [blog post of Thomas Kipf](https://tkipf.github.io/graph-convolutional-networks/) on the GCNs implementation.\n",
        "\n",
        "As stated by Kipf, the propagation rule for each layer of a GCN is the following\n",
        "\n",
        "$f(H^{(l)}, A) = \\sigma \\Big( \\color{red}D^\\color{red}{-1/2}\\color{red}A\\color{red}D^\\color{red}{-1/2} H^{(l)}W^{(l)} \\Big)$\n",
        "\n",
        "Consider a single random walk step, we consider the power 1 of the $A_{\\text{reduced}}$ matrix, that corresponds to taking the normalized average of neighboring node features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2lBseVWEnkOf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resources\n",
        "* Laplacin matrix on Wikipedia: https://en.wikipedia.org/wiki/Laplacian_matrix.\n",
        "* Graph Convolutional Networks blog post: https://tkipf.github.io/graph-convolutional-networks/\n"
      ]
    }
  ]
}